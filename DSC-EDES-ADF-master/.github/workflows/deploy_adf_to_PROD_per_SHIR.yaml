name: "Deploy ADF - duplicate services per SHIR"
on:
  workflow_dispatch:
    inputs:
      environment:
        required: true
        type: environment

permissions:
      id-token: write
      contents: read
      
jobs: 
  build-and-deploy: 
    runs-on: [self-hosted, EMEA-VM]
    environment:
      name: ${{ inputs.environment }}
    steps:
    - name: checkout branch with artifacts
      uses: actions/checkout@v3
      with:
        fetch-depth: 0
        ref: 'adf_publish'
    - name: setup offline actions
      run: |
        cp -R /home/r2eA9YadfdFpDcF/actions-offline .
        pwd
        ls actions-offline
    - name: 'Run Azure CLI commands for login'
      run: |
          source $CONDA_INIT_SCRIPT
          conda activate synapse_deploy_py38
          az login --identity
    - name: get IR info
      run: |
        # run pipeline get IR info
        runInfo=$( az synapse pipeline create-run  \
        --workspace-name dscemedesws0ppldnsazr \
        --name get_IR_info )
        runId=$(echo $runInfo | jq .runId | tr -d '"')

        # check status of the pipeline
        sleep 60
        runResult=$(az synapse pipeline-run show --workspace-name dscemedesws0ppldnsazr --run-id $runId)
        runStatus=$(echo $runResult | jq .status | tr -d '"')
        
        ## run check 20 times, max of waiting time is 20 minutes
        for i in {0..20}
        do 
        if [ $runStatus == "InProgress" ]
        then
        sleep 60
        runResult=$(az synapse pipeline-run show --workspace-name dscemedesws0ppldnsazr --run-id $runId)
        runStatus=$(echo $runResult | jq .status | tr -d '"')
        fi
        done

        # fail workflow if run did not succeed
        if [ $runStatus != "Succeeded" ]
        then
        exit 1
        fi
        
        # print result
        echo $runResult | jq .pipelineReturnValue >> IR_INFO.json
    - name: replace folder name
      run: |
        source $CONDA_INIT_SCRIPT
        conda activate synapse_deploy_py38
        python replace_folder_name.py
    - name: duplicate services per SHIR
      run: |
        source $CONDA_INIT_SCRIPT
        conda activate synapse_deploy_py38
        python duplicate_per_SHIR.py
    - name: Deploy resources
      uses: ./actions-offline/Azure-data-factory-deploy-action-390b781
      with:
        resourceGroupName: ${{ vars.ADF_RESOURCE_GROUP }}
        dataFactoryName: ${{ vars.ADF_NAME }}
        armTemplateFile: ./dscemedesadf0tpldnsazr/ARMTemplateForFactoryProd.json
        armTemplateParametersFile: ./dscemedesadf0tpldnsazr/ARMTemplateParametersForFactory.json
        additionalParameters: '${{ vars.ADF_PROD_PARAMETERS }}'
        # skipAzModuleInstallation: true [optional]
    - name: stop all triggers in ADF PROD
      run: |
        source $CONDA_INIT_SCRIPT
        conda activate synapse_deploy_py38
        az login --identity
        az datafactory trigger query-by-factory --factory-name ${{ vars.ADF_NAME }} --resource-group ${{ vars.ADF_RESOURCE_GROUP }} --query "{triggers:[value][0][].name,token:continuationToken}" > query_result.json
        token=$(jq -r '.token' query_result.json)
        jq -r '.triggers[]' query_result.json > all_triggers.txt
        
        while [ "$token" != "null" ]
        do
        az datafactory trigger query-by-factory --factory-name ${{ vars.ADF_NAME }} --resource-group ${{ vars.ADF_RESOURCE_GROUP }} --continuation-token $token --query "{triggers:[value][0][].name,token:continuationToken}" > query_result.json
        token=$(jq -r '.token' query_result.json)
        jq -r '.triggers[]' query_result.json >> all_triggers.txt
        done
       
        for trigger in $(cat all_triggers.txt); do az datafactory trigger stop --name $trigger --factory-name ${{ vars.ADF_NAME }} --resource-group ${{ vars.ADF_RESOURCE_GROUP }}; done
    - name: Start ADF PROD triggers based on active_triggers.txt
      run: |
        source $CONDA_INIT_SCRIPT
        conda activate synapse_deploy_py38
        az login --identity
        for trigger in $(cat ${{ vars.ACTIVE_TRIGGERS_FILE }}); do az datafactory trigger start --name $trigger --factory-name ${{ vars.ADF_NAME }} --resource-group ${{ vars.ADF_RESOURCE_GROUP }}; done
